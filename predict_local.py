import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# --- Step 1: Load the trained model ---
model = load_model("arabic_characters_model.h5")
print("âœ… Model loaded successfully.")

# --- Step 2: Define Arabic character labels ---
arabic_characters = ['Ø§', 'Ø¨', 'Øª', 'Ø«', 'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±',
                     'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸', 'Ø¹', 'Øº', 'Ù',
                     'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'ÙŠ']

# --- Step 3: Load and preprocess test data from GitHub ---
print("ğŸ“¥ Loading test data from GitHub...")

# Raw URLs of the CSV files on GitHub
x_test_url = "https://raw.githubusercontent.com/Bilal-Belli/ArabicAlphabetRecognizerCNN/refs/heads/main/Datasets/csvTestImages%203360x1024.csv"
y_test_url = "https://raw.githubusercontent.com/Bilal-Belli/ArabicAlphabetRecognizerCNN/refs/heads/main/Datasets/csvTestLabel%203360x1.csv"

# Load data directly from GitHub
x_test = pd.read_csv(x_test_url, header=None)
y_test = pd.read_csv(y_test_url, header=None)

# Normalize and reshape data
x_test = x_test / 255.0
x_test = x_test.values.reshape(-1, 32, 32, 1)
y_true = y_test.values.flatten()

print(f"ğŸ§ª Test samples: {x_test.shape[0]}")

# --- Step 4: Run predictions ---
print("ğŸ¤– Predicting on test data...")
y_pred_probs = model.predict(x_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)

# --- Step 5: Show prediction results for first 25 samples ---
plt.figure(figsize=(15, 15))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    img = x_test[i].reshape(32, 32).T  # transpose for correct orientation
    true_lbl = arabic_characters[y_true[i] - 1]
    pred_lbl = arabic_characters[y_pred_classes[i] - 1]
    plt.imshow(img, cmap='gray')
    plt.title(f'True: {true_lbl}\nPred: {pred_lbl}')
    plt.axis('off')

plt.tight_layout()
plt.show()
